#! /usr/bin/env python3

# ==========================================================================================================================================================
#  Copyright 2021 Carnegie Mellon University.
#
#  NO WARRANTY. THIS CARNEGIE MELLON UNIVERSITY AND SOFTWARE ENGINEERING INSTITUTE MATERIAL IS FURNISHED ON AN "AS-IS"
#  BASIS. CARNEGIE MELLON UNIVERSITY MAKES NO WARRANTIES OF ANY KIND, EITHER EXPRESSED OR IMPLIED, AS TO ANY MATTER
#  INCLUDING, BUT NOT LIMITED TO, WARRANTY OF FITNESS FOR PURPOSE OR MERCHANTABILITY, EXCLUSIVITY, OR RESULTS OBTAINED
#  FROM USE OF THE MATERIAL. CARNEGIE MELLON UNIVERSITY DOES NOT MAKE ANY WARRANTY OF ANY KIND WITH RESPECT TO FREEDOM
#  FROM PATENT, TRADEMARK, OR COPYRIGHT INFRINGEMENT. Released under a BSD (SEI)-style license, please see license.txt
#  or contact permission@sei.cmu.edu for full terms.
#
#  [DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution.  Please see
#  Copyright notice for non-US Government use and distribution.
#
#  This Software includes and/or makes use of the following Third-Party Software subject to its own license:
#  1. Pytorch (https://github.com/pytorch/pytorch/blob/master/LICENSE) Copyright 2016 facebook, inc..
#  2. NumPY (https://github.com/numpy/numpy/blob/master/LICENSE.txt) Copyright 2020 Numpy developers.
#  3. Matplotlib (https://matplotlib.org/3.1.1/users/license.html) Copyright 2013 Matplotlib Development Team.
#  4. pillow (https://github.com/python-pillow/Pillow/blob/master/LICENSE) Copyright 2020 Alex Clark and contributors.
#  5. SKlearn (https://github.com/scikit-learn/sklearn-docbuilder/blob/master/LICENSE) Copyright 2013 scikit-learn
#      developers.
#  6. torchsummary (https://github.com/TylerYep/torch-summary/blob/master/LICENSE) Copyright 2020 Tyler Yep.
#  7. adversarial robust toolbox (https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/LICENSE)
#      Copyright 2018 the adversarial robustness toolbox authors.
#  8. pytest (https://docs.pytest.org/en/stable/license.html) Copyright 2020 Holger Krekel and others.
#  9. pylint (https://github.com/PyCQA/pylint/blob/master/COPYING) Copyright 1991 Free Software Foundation, Inc..
#  10. python (https://docs.python.org/3/license.html#psf-license) Copyright 2001 python software foundation.
#
#  DM20-1149
#
# ==========================================================================================================================================================

import sys
import json
import logging
import argparse

import juneberry.plotting
import juneberry.debugging
import juneberry.config_loader
import juneberry.filesystem as jbfs
import juneberry.scripting as jbscripting
import juneberry.pytorch.classifier_trainer
from juneberry.config.dataset import DatasetConfig
from juneberry.config.training import TrainingConfig


def setup_args(parser) -> None:
    """
    Adds arguments to the parser
    :param parser: The parser in which to add arguments.
    """
    parser.add_argument('modelName', help='Name of the directory in models containing the \'config.json\' in '
                                          'workspace models directory.')
    parser.add_argument('--dryrun', default=False, action='store_true',
                        help='Flag to initiate dry run mode. ')
    parser.add_argument('--version', default="",
                        help='Optional parameter used to control which version of a data set to use.')
    parser.add_argument('--nopaging', default=False, action='store_true',
                        help='Set to true to disable data set paging and load all at once.')


def main():
    # Setup and parse all arguments.
    parser = argparse.ArgumentParser(description="Performs the training defined in a Juneberry training "
                                                 "configuration file.")
    setup_args(parser)
    jbscripting.setup_args(parser)
    args = parser.parse_args()

    # The model manager helps us find all the files and directories
    model_manager = jbfs.ModelManager(args.modelName, args.version)

    log_prefix = ""
    log_file = model_manager.get_training_log()
    if args.dryrun:
        log_prefix = "<< DRY_RUN >> "
        log_file = model_manager.get_training_dryrun_log_path()

    # Use the config file to set up the workspace, data and logging
    jbscripting.setup_for_single_model(args, log_file, log_prefix, model_manager)

    # Kick off the logging
    logging.info("Beginning training with model: " + args.modelName)

    # Load the config files, check and aggregate configuration options
    logging.info(f"Loading config files...")
    with open(model_manager.get_model_config()) as config_file:
        logging.info(f"...training config - {model_manager.get_model_config()}...")
        training_config = TrainingConfig(args.modelName, json.load(config_file))
    with open(training_config.data_set_path) as config_file:
        logging.info(f"...data set config - {training_config.data_set_path}...")
        data_set_config = DatasetConfig(json.load(config_file), training_config.data_set_path.parent)

    # If we have num workers in the training config, then we need to set that override
    if 'numWorkers' in training_config.get('hints', {}):
        num_workers = training_config['hints']['numWorkers']
        logging.warning(f"Overriding number of workers. Found {num_workers} in TrainingConfig")
        juneberry.NUM_WORKERS = num_workers

    # This trainer will get assigned depending on what type of task is being performed.
    trainer = None

    # Get the type of training from the config. If the config doesn't indicate the type, assume
    # classification.
    training_type = training_config.get('task', None)

    if training_type is None:
        logging.warning(f"Training config is missing the \'task\' field. Assuming the task is \"classification\".")
        training_type = "classification"

    # If the task type is classification, set up a ClassifierTrainer to do the work
    if training_type == "classification":
        logging.info(f"Preparing a trainer for a classification task...")
        if training_config.platform == "pytorch":
            trainer = juneberry.pytorch.classifier_trainer.ClassifierTrainer(model_manager, training_config,
                                                                             data_set_config, dry_run=args.dryrun,
                                                                             no_paging=args.nopaging)
        else:
            logging.error(f"Unrecognized platform {training_config.platform}. EXITING")
            sys.exit(-1)

    # If a trainer was set, then perform the training
    if trainer is not None:
        trainer.train_model()


if __name__ == "__main__":
    main()
